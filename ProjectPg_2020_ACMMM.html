<!DOCTYPE HTML>
<!--
	Photon by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Pravin Nagar</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">


		<!-- Header -->

			<section id="header">
				<div class="container">

				<h1><strong>Concept Drift Detection for Multivariate Data Streams and Temporal Segmentation of Daylong Egocentric Videos</strong> </h1><br>
					<h3>Pravin Nagar , Mansi Khemka , and Chetan Arora </h3><br><br>
						<h5>( ACMMM 2020 )</h5>

					<style>
            a {
        			/*color: #8ebf42;*/
							color: inherit;
      				}
    			</style>
				</div>
			</section>


<!--Project Description-->
<section id="ProjectPg_2020_ACMMM" class="main style1">
<div class="container">
	<div  class="content">
		<h2>Abstract</h2>
		<p>The long and unconstrained nature of egocentric videos makes it imperative to use temporal segmentation as an important pre-processing step for many higher-level inference tasks. Activities of the wearer in an egocentric video typically span over hours and are often separated by slow, gradual changes. Furthermore, the change of camera viewpoint due to the wearer's head motion causes frequent and extreme, but, spurious scene changes. The continuous nature of boundaries makes it difficult to apply traditional Markov Random Field (MRF) pipelines relying on temporal discontinuity, whereas deep Long Short Term Memory (LSTM) networks gather context only upto a few hundred frames, rendering them ineffective for egocentric videos. In this paper, we present a novel unsupervised temporal segmentation technique especially suited for day-long egocentric videos. We formulate the problem as detecting concept drift in a time-varying, non i.i.d. sequence of frames. Statistically bounded thresholds are calculated to detect concept drift between two temporally adjacent multivariate data segments with different underlying distributions while establishing guarantees on false positives. Since the derived threshold indicates confidence in the prediction, it can also be used to control the granularity of the output segmentation. Using our technique, we report significantly improved state of the art f-measure for daylong egocentric video datasets, as well as photostream datasets derived from them: HUJI~(73.01%, 59.44%), UTEgo~(58.41%, $60.61%) and Disney~(67.63%, 68.83%).
		</p>

		<h2>Methodology</h2>
		<img src="projects/2020_ACMMM/methodology.png" alt="" width="1100" height="700"/><br><br><br>


		<h2>Visualization</h2>
			<p>The following figure shows a qualitative representation of closeness of boundaries predicted by the proposed approach, ADaptive WINdowing (ADWIN), Contextual Event Segmentation (CES) to ground truth boundaries from specific portions of Huji (first row), UTEgo (second row), and Disney (third row) datasets.</p>
    		<img src="projects/2020_ACMMM/visualization.png" alt="" width="1100" height="500"/><br><br><br>

		<h2>Code</h2>
			<ul>
				<li>The software implementation of this project can be found on <a href="https://github.com/Pravin74/temporal_video_segmentation_code">GitHub repository</a>.</li>
				<li>The CNN features to reproduce the results can be found <a href="https://drive.google.com/drive/folders/1L0I9wZhYnh2xV8e8A3QFklYU5pAk8F5l">here</a>.</li>
			</ul>

		<h2>Supplementary Material</h2>
			<ul>
				<li>The supplementary material can be found <a href="https://pravin74.github.io/TVS/supplementary.pdf">here</a>.</li>
				<li>The video demonstration of the proposed framework on a video sequence of the HUJI dataset is avialable <a href="https://www.youtube.com/watch?v=tHxj_bR73Rs">here</a>. </li>
			</ul>

		<h2>Annotations</h2>
			<p>The ground truth annotations for Disney and UTEgo datasets can be downloaded from <a href="https://drive.google.com/drive/folders/1cZ6Yi3YQxo5USR1ti_afO560sqhV9pVN">here</a>.</p>

		<h2>Citation</h2>
			<ul>
				<li><b>ACM Reference format:</b><br>
				Pravin Nagar, Mansi Khemka, and Chetan Arora. 2020. Concept Drift Detection for Multivariate Data Streams and Temporal Segmentation of Daylong Egocentric Videos. In Proceedings of the 28th ACM International Conference on Multimedia (MM '20). Association for Computing Machinery, New York, NY, USA, 1065–1074.
				DOI:<a href="https://doi.org/10.1145/3394171.3413713">https://doi.org/10.1145/3394171.3413713</a>
			</li><br>

				<li><b>Bibtex:</b><br>
					<pre>
@inproceedings{10.1145/3394171.3413713,
author = {Nagar, Pravin and Khemka, Mansi and Arora, Chetan},
title = {Concept Drift Detection for Multivariate Data Streams and Temporal Segmentation of
Daylong Egocentric Videos},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394171.3413713},
doi = {10.1145/3394171.3413713},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {1065–1074},
numpages = {10},
series = {MM '20}
}</pre>
				</li>
			</ul>








</div>
</section>

		<!-- Footer -->
			<section id="footer">

				<ul class="icons">
					<!--	<li><a href="#" class="ai ai-google-scholar"><span class="label">Google Scholar</span></a></li>-->
						<li><a href="https://www.linkedin.com/in/pravin-nagar-90886a124/" class="icon brands fa fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/Pravin74" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="https://twitter.com/NAGAR_PRAVIN" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://medium.com/@pravinn_82098" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
						<li><a href="https://www.facebook.com/pravin.nagar" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
					<!--	<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="#" class="icon solid alt fa-envelope"><span class="label">Email</span></a></li>-->

				</ul>
				<i>pravinn@iiitd.ac.in</i><br><br>
				<ul class="copyright">
					<li>&copy; Pravin Nagar <script>document.write( new Date().getUTCFullYear() );</script></li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
