<!DOCTYPE html>
<!-- saved from url=(0042)https://sagarverma.github.io/dynamics.html -->
<html lang="en-gb" dir="ltr" class="com_content view-article layout-blog itemid-118 j39 mm-hover  no-touch"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<meta name="keywords" content="computer vision, research">
	<meta name="author" content="Pravin Nagar">
	<meta name="description" content="Computer Vision & Machine Learning (CVML) is a research centre at IIIT Delhi.">
	<meta name="generator" content="Joomla! - Open Source Content Management">
	<title>Generating Personalized Summaries of Day Long Egocentric Videos</title>
	<link href="./stylesandscripts/bootstrap.css" rel="stylesheet" type="text/css">
	<link href="./stylesandscripts/system.css" rel="stylesheet" type="text/css">
	<link href="./stylesandscripts/template.css" rel="stylesheet" type="text/css">
	<link href="./stylesandscripts/megamenu.css" rel="stylesheet" type="text/css">
	<link href="./stylesandscripts/font-awesome.min.css" rel="stylesheet" type="text/css">
	<link href="./stylesandscripts/magazine.css" rel="stylesheet" type="text/css">
	<script src="./stylesandscripts/jquery.min.js" type="text/javascript"></script>
	<script src="./stylesandscripts/jquery-noconflict.js" type="text/javascript"></script>
	<script src="./stylesandscripts/jquery-migrate.min.js" type="text/javascript"></script>
	<script src="./stylesandscripts/caption.js" type="text/javascript"></script>
	<script src="./stylesandscripts/bootstrap.js" type="text/javascript"></script>
	<script src="./stylesandscripts/jquery.tap.min.js" type="text/javascript"></script>
	<script src="./stylesandscripts/script.js" type="text/javascript"></script>
	<script src="./stylesandscripts/menu.js" type="text/javascript"></script>
	<script src="./stylesandscripts/nav-collapse.js" type="text/javascript"></script>
	<script type="text/javascript">

		jQuery(window).on('load',  function() {
				new JCaption('img.caption');
			});

		jQuery(function($){ initTooltips(); $("body").on("subform-row-add", initTooltips); function initTooltips (event, container) { container = container || document;$(container).find(".hasTooltip").tooltip({"html": true,"container": "body"});} });
	</script>

	<style type="text/css">

		.card { display: inline-block; vertical-align: top; width: 500px; height: 150px; position: relative; overflow: hidden; margin: 20px; background: #FFF; box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.16), 0 2px 10px 0 rgba(0, 0, 0, 0.12); color: #272727; border-radius: 2px;}


		.card .image { position: relative; height: 150px; width: 150px; float: left;}


		.card .image img { border-radius: 2px 0 0 2px; position: relative; left: 0; right: 0; top: 0; bottom: 0; height: 100%; -moz-transition:-moz-transform 0.5s ease-in; -webkit-transition:-webkit-transform 0.5s ease-in; -o-transition:-o-transform 0.5s ease-in; transition: 0.5s ease-in;}

		.card .image img:hover{ -moz-transform:scale(.95); -webkit-transform:scale(.95); -o-transform:scale(.95); transform:scale(.95);}/* .card img:hover{ -webkit-transform: rotateZ(-10deg); -ms-transform: rotateZ(-10deg); transform: rotateZ(-10deg); transition: 1s ease;}*/

		.card .title { padding-top: 10px !important; line-height: 24px; font-size: 18px; font-weight: 600; position: relative; top: 10px; padding: 20px; font-variant: small-caps;}


		.card .content { font-size: 13; width: 350px; float: left; padding: 20px; font-weight: 300; border-radius: 0 2px 2px 0;}.card p { margin: 0;}


		.card a { font-size: 13px; color: #29739D; margin-right: 20px; -webkit-transition: color 0.3s ease; transition: color 0.3s ease; text-transform: uppercase; text-decoration: none;}

		.card .card-footer { text-align: right; width: 350px; position: absolute; bottom: 0; left: 150px; border-top: 1px solid rgba(160, 160, 160, 0.2); margin: 0; padding-left: 20px; padding-right: 10px;}

		.card .card-footer a { color: #ffab40; margin-right: 20px; -webkit-transition: color 0.3s ease; transition: color 0.3s ease; text-transform: uppercase; text-decoration: none;}

		.recents { font-size: 16px; padding: 7px 15px; background-color: #eeeeee;}

		.recent-updates-module { height: 400px; overflow: auto; text-align: justify;}</style>


<!-- META FOR IOS & HANDHELD -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">


	<style type="text/stylesheet">
		@-webkit-viewport   { width: device-width; }
		@-moz-viewport      { width: device-width; }
		@-ms-viewport       { width: device-width; }
		@-o-viewport        { width: device-width; }
		@viewport           { width: device-width; }
	</style>


	<script type="text/javascript">
		//<![CDATA[
		if (navigator.userAgent.match(/IEMobile\/10\.0/)) {
			var msViewportStyle = document.createElement("style");
			msViewportStyle.appendChild(
				document.createTextNode("@-ms-viewport{width:auto!important}")
			);
			document.getElementsByTagName("head")[0].appendChild(msViewportStyle);
		}

	</script>


<meta name="HandheldFriendly" content="true">
<meta name="apple-mobile-web-app-capable" content="YES">
<!-- //META FOR IOS & HANDHELD -->




<!-- Le HTML5 shim and media query for IE8 support -->
<!--[if lt IE 9]>
<script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
<script type="text/javascript" src="/plugins/system/t3/base-bs3/js/respond.min.js"></script>
<![endif]-->

<!-- You can add Google Analytics here or use T3 Injection feature -->

<!--[if lt IE 9]>
<link rel="stylesheet" href="/templates/purity_iii/css/ie8.css" type="text/css" />
<![endif]-->	</head>

<body data-gr-c-s-loaded="true">

<div class="t3-wrapper magazine"> <!-- Need this wrapper for off-canvas menu. Remove if you don't use of-canvas -->


<div id="t3-mainbody" class="container t3-mainbody">
	<div class="row">

		<!-- MAIN CONTENT -->
		<div id="t3-content" class="t3-content col-xs-12">


<div class="item-page clearfix">


<!-- Article -->
<article itemscope="" itemtype="http://schema.org/Article">
	<meta itemprop="inLanguage" content="en-GB">
	<meta itemprop="url" content="/research/projects/cvit-projects/badminton-analytics">

	<section class="article-content clearfix" itemprop="articleBody">
		<h3 style="text-align: center; color:#000000"><strong><u>Generating Personalized Summaries of Day Long Egocentric Videos</u></strong></h3><br>
		<div class="row">
				<center>
		          <div class="col-md-8 no-pad">
		            <div class="authors">

		              <a target="blank" href="https://pravin74.github.io/">Pravin Nagar </a>,
		              <a target="blank" href="#">    Anuj Rathore    </a>,
		              <a target="blank" href="https://faculty.iiit.ac.in/~jawahar/">  C.V. Jawahar</a>,
									<a target="blank" href="https://www.cse.iitd.ac.in/~chetan/">    Chetan Arora</a>

		            </div>
		          </div>
    </center>
    </div>
<h3 style="color: #0e083b"><b>Abstract</b></h3>
<div style="text-align: justify;color: #083e40">The popularity of egocentric cameras and their always-on nature has lead to the abundance of day-long first-person videos. The presence of extreme shake and highly redundant nature of these videos make them difficult to watch from beginning to end and requiring summarization tools for their efficient consumption. However, traditional summarization techniques developed for static surveillance videos, or highly curated sports videos and movies are, either, not suitable or simply do not scale for such hours long videos in the wild. On the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. In this paper, we present a novel unsupervised reinforcement learning framework to summarize egocentric videos both in terms of length as well as the content. The proposed framework facilitates to incorporate various types of prior preferences such as faces, places, or scene diversity as well as interactive user choice in terms of including or excluding the particular type of content. Our approach can also be adapted to generate summaries of various lengths making it possible to view even 1-minute summaries of oneâ€™s entire day. When using the facial saliency-based reward, we show that our approach generates summaries focusing on social interactions, similar to the current state-of-the-art (SOTA). Quantitative comparison on the benchmark Disney dataset shows that our method achieves significant improvement in Relaxed F-Score (RFS) ( 29.60 compared to 19.21 from SOTA) and BLEU score ( 11.55 vs. 10.64 from SOTA). Finally, we show that our technique can be applied for summarizing traditional, short, hand-held videos as well, where we improve the SOTA F-score on benchmark SumMe and TVSum datasets from 41.4 to 46.40 and 57.6 to 58.3 respectively.</div>
<p>&nbsp;</p>
<hr>
<h3 style="color: #0e083b"><b>Architecture</b></h3><br>
<div><img style="display: block; margin-left: auto; margin-right: auto;border: solid 2px black; width: 100%" src="Architecture.png" alt="IMG"><center><small></small></center></div>
<br><br>

<hr>
<div>
<h3 style="color: #0e083b"><b>Code</b></h3>
<p>The software implementation of this project can be found on <a href="https://github.com/Pravin74/interact_summ_code">GitHub repository</a>. The implementation is based on PyTorch library. </p>
</div>
<hr>

<div>
<h3 style="color: #0e083b"><b>Supplementary Material</b></h3>
<p>The supplementary material can be found<a href="Interactive_summ_supp.pdf"> here </a></p>
</div>

<hr>
<div>
<h3 style="color: #0e083b"><b>Datasets</b></h3>
<div>
<p>The Feature extraction process and feature loading from h5py files is explained in the <a href="ReadMe_dataset_preparation.pdf"> ReadMe. </a></p>
</div>
<div class="row">

	<div class="col-xs-3">
		<li style="padding-left: 50%"><a href="http://ai.stanford.edu/~alireza/Disney/">DISNEY: </a></p></li>
		<li style="padding-left: 50%"><a href="http://vision.cs.utexas.edu/projects/egocentric_data/UT_Egocentric_Dataset.html">UTE: </a></p></li>
		<li style="padding-left: 50%"><a href="http://www.vision.huji.ac.il/egoseg/videos/dataset.html">HUJI: </a></p></li>

	</div>

	<div class="col-xs-3">
		<ul><a href="https://drive.google.com/drive/folders/1-Q-ur3TAfQi-WIfkAYn-dG3TUpdnR_K6">CNN Features</a></p></ul>
		<ul><a href="#">CNN Features</a></p></ul>
		<ul><a href="#">CNN Features</a></p></ul>
</div>
<div class="col-xs-3">
	<ul><a href="https://drive.google.com/drive/folders/1-Q-ur3TAfQi-WIfkAYn-dG3TUpdnR_K6">C3D Features</a></p></ul>
	<ul><a href="https://drive.google.com/drive/folders/1FswxUAgKBhx02pUNv610-kG7lbE-PJxu">C3D Features</a></p></ul>
	<ul><a href="https://drive.google.com/drive/folders/199UmwjLnqTGLSo7QgaPsaYFAAxieqSLY">C3D Features</a></p></ul>
	</div>
<div class="col-xs-3">
	<ul><a href="http://ai.stanford.edu/~syyeung/videoset.html">Annotations</a></p></ul>
	<ul><a href="http://ai.stanford.edu/~syyeung/videoset.html">Annotations</a></p></ul>
	<ul>NA</p></ul>
</div>
</div>
</div>


<!-- Inserting tabel  -->
<hr>
<div>
<h3 style="color: #0e083b"><b>Video Demonstration of Interactive Summarization</b></h3>
<p> The table below demonstrates few demos of generated summaries under different feedbacks. </p>
<!-- <style>
table, th, td {
  border: 1px;
  padding: 5px;
}
table {
  border-spacing: 15px;
}
</style> -->

<style>
table, th, td {
  border-style: solid;
  border-color: gray;
  border-collapse: collapse;
}
th, td {
  padding: 7px;
  text-align: center;
}
</style>

<table class="tg">
<thead>
  <tr>
    <th class="tg-lboi">Events</th>
    <th class="tg-9wq8">Video</th>
    <th class="tg-9wq8">Dataset </th>
    <th class="tg-baqh">Summary without feedback</th>
    <th class="tg-baqh">Feedback1</th>
    <th class="tg-baqh">Feedback2</th>
    <th class="tg-0lax">Remarks</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky">Dinner</td>
    <td class="tg-c3ow">Alin Day 1</td>
    <td class="tg-c3ow">Disney</td>
		<td>
			<div id="over"> No Feedback</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/mDyTfHzIboA">link</iframe>

		</td>
	  	<td>
	  		<div id="over">Dinner Included</div>
	  		<iframe width="277" height="208" src="https://www.youtube.com/embed/VnPu-uPMTt0">Dinner included</iframe>
	  	</td>

	  	<td>
	  		<div id="over">Dinner Exlcuded</div>
	  		<iframe width="277" height="208" src="https://www.youtube.com/embed/IKVnlbCikII">Dinner excluded</iframe>
		</td>

    <td class="tg-0lax">The video demonstrations are corresponding to Fig. 7 in main manuscript</td>
  </tr>

  <tr>
    <td class="tg-0pky">Driving</td>
    <td class="tg-c3ow">P01</td>
    <td class="tg-c3ow">UTE</td>
		<td>
			<div id="over">No Feedback </div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/5csxmeLR0Ss">Link</iframe>
		</td>
		<td>
			<div id="over">Driving Included</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/CTVBU1iPPow">Driving Included</iframe>
		</td>
		<td>
			<div id="over">Driving Exlcuded</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/ZJo7Dw9i7DU">Driving excluded</iframe>
		</td>

		<td class="tg-0lax">The video demonstrations are corresponding to Fig. 9(b,c, and d) in supplementary material </td>
  </tr>

  <tr>
    <td class="tg-0pky"><span style="font-weight:400;font-style:normal">Preparing food & Driving </span></td>
    <td class="tg-c3ow">P01</td>
    <td class="tg-c3ow">UTE</td>
		<td>
			<div id="over"> No feedback</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/Um2it_Xc7zA">link</iframe>

		</td>
		<td>
			<div id="over">Driving exlcuded and Prep. food included</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/UH2DBNhzz6E">Driving exlcuded and Prep. food included</iframe>
		</td>
		<td>
			<div id="over">Driving included and Prep. food excluded</div>
			<iframe width="277" height="208" src="https://www.youtube.com/embed/RHT2pWVTRRs">Driving included and Prep. food excluded</iframe>
		</td>

    <td class="tg-0lax">The video demonstrations are corresponding to Fig. 9(b,e, and f) in supplementary material</td>
  </tr>

</tbody>
</table>
<br/>
<p>We have also created the GUI for interactive video summarization. The video demonstrates the use of GUI for taking positive and negative feedbacks.</p>
<iframe width="480" height="360" src="https://www.youtube.com/embed/f31fnnJpSzE"> </iframe>
</div>

<hr>
<!-- inserting table ended -->
<div>
<h3 style="color: #0e083b"><b>Video Demonstration of Video summarization using various plugins </b></h3>
<iframe width="480" height="360" src="https://www.youtube.com/embed/0h7PzMSb_Ak">link</iframe>
</div>

<hr>

<h3 style="color: #0e083b"><b>More Visualization</b></h3><br>
<div style="text-align: justify;color: #083e40">The figure demonstrates the visualization of the interactive summarization of the 'P01â€™ video sequence of the UTE dataset. Each bar represents 10 seconds of time interval. (a)-(e) shows different summaries when two events namely 'preparing foodâ€™ and 'drivingâ€™ are included/excluded in the summary. We can observe that (c) has more driving sub-shots compared to (b), whereas in (d) the bars in the driving sub-shots are reduced considerably. Similarly, for (e) we get peaks in the 'preparing foodâ€™ area whereas the bars in the driving area are reduced. The opposite is seen in the (d).</div>
<br>
<div><img style="display: block; margin-left: auto; margin-right: auto;border: solid 2px black;width: 100%" src="visualization.png" alt="IMG"><center><small></small></center></div>
<hr>
<br>
<h3 style="color: #0e083b"><b>User Study</b></h3><br>
<div style="text-align: justify;color: #083e40">The table shows the Likert score of 1 (Extremely dissatisfied) to 5 (Extremely satisfied) given by the participants when specific events are included or excluded in the summary with user comments on the personalized summary. S0X-SY represents subject â€˜Xâ€™ in scenario â€˜Yâ€™. It is observed that sometimes the user sees the excluded part in the personalized summary. This is because the interactive reward personalized the summary but at the same time distinctiveness-indicative reward that tries to maintain the global context. This can be handled by fine-tuning the weights of A and B discussed in interactive reward.</div>
<br>
 <iframe src="Interactive_user_feedback.pdf" width="100%" height="500px">
 </iframe>
 <hr>

<h3 style="color: #0e083b"><b>Related Publications</b></h3>
<ul>
<li>Anuj Rathore*, Pravin Nagar* , Chetan Arora, and C. V. Jawahar. "Generating 1 Minute Summaries of Day Long Egocentric Videos" ACMMM 2019.</li>
</ul>
<hr>
<h3>Bibtex</h3>
<p>If you use this work, please cite these works :</p>
<div>

<pre style="border-style: solid; border-width: 1px;"> @article{nagar2021generating,
	title={Generating Personalized Summaries of Day Long Egocentric Videos},
	author={Nagar, Pravin and Rathore, Anuj and Jawahar, CV and Arora, Chetan},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2021},
	publisher={IEEE}}
	<pre style="border-style: solid; border-width: 0px;"> @inproceedings{rathore2019generating,
	  title={Generating 1 Minute Summaries of Day Long Egocentric Videos},
	  author={Rathore, Anuj and Nagar, Pravin and Arora, Chetan and Jawahar, CV},
	  booktitle={Proceedings of the 27th ACM International Conference on Multimedia},
	  pages={2305--2313},
	  year={2019}}
	</pre>
</div>
<hr>

<hr>
	</section>

	</article>

</div>


</div>

	</div>
</div>

</div>


</body></html>
